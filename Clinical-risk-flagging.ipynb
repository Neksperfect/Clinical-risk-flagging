{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39cd978-3533-4784-9cd9-c9bc272c926b",
   "metadata": {},
   "source": [
    "## Business Context\n",
    "\n",
    "In clinical laboratory workflows, automated test systems are used to process large volumes of samples.\n",
    "The most critical failure in this setting is a false negative — a high-risk test result that is not flagged for manual review.\n",
    "\n",
    "The goal of this project is to build a decision-support model that flags test results for manual review,\n",
    "prioritizing recall to minimize false negatives, even if this increases manual review workload.\n",
    "\n",
    "This model does not replace clinicians.\n",
    "It supports prioritization so that high-risk cases receive human attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8251711-507d-4123-bcda-fc96914fc76d",
   "metadata": {},
   "source": [
    "## Data and Target Definition\n",
    "\n",
    "Each row in the dataset represents a diagnostic test derived from image-based measurements of cell nuclei.\n",
    "\n",
    "The dataset contains multiple numeric features describing shape, texture, and structural characteristics.\n",
    "\n",
    "Target variable:\n",
    "- flag_for_review = 1 → requires manual clinical review\n",
    "- flag_for_review = 0 → does not require review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf68682-2dff-42ad-9cbe-6955c450e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>flag_for_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  flag_for_review  \n",
       "0          0.4601                  0.11890                0  \n",
       "1          0.2750                  0.08902                0  \n",
       "2          0.3613                  0.08758                0  \n",
       "3          0.6638                  0.17300                0  \n",
       "4          0.2364                  0.07678                0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Create DataFrame\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='flag_for_review')\n",
    "\n",
    "# Combine into one DataFrame\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbdb065-6efe-4668-ab96-66dbdf470603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>flag_for_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension  flag_for_review  \n",
       "count               569.000000       569.000000  \n",
       "mean                  0.083946         0.627417  \n",
       "std                   0.018061         0.483918  \n",
       "min                   0.055040         0.000000  \n",
       "25%                   0.071460         0.000000  \n",
       "50%                   0.080040         1.000000  \n",
       "75%                   0.092080         1.000000  \n",
       "max                   0.207500         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51bdaac-da88-429a-9089-4ad3ab97ec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flag_for_review\n",
       "1    357\n",
       "0    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Distribution\n",
    "# We ask the question, how many safe cases vs dangerous cases do we have\n",
    "\n",
    "df['flag_for_review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89ab6a24-d242-4752-b4b9-a050da7eca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flag_for_review\n",
       "1    0.627417\n",
       "0    0.372583\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['flag_for_review'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a593b-7fd7-4316-a939-86dbeea2dce0",
   "metadata": {},
   "source": [
    "## Model Stability — Cross Validation\n",
    "\n",
    "To verify that the model’s performance is not dependent on a single train-test split,\n",
    "5-fold cross-validation is used.\n",
    "\n",
    "Recall is measured across folds to assess stability.\n",
    "Consistently high recall with low variance indicates that the model generalizes reliably\n",
    "and does not rely on favorable data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31de2c6-8a86-4bb9-9d91-327ef1265de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall per fold: [0.95774648 0.98591549 0.98611111 0.97222222 1.        ]\n",
      "Mean recall: 0.980399061032864\n",
      "Recall std: 0.01433356562133385\n"
     ]
    }
   ],
   "source": [
    "# Now that we have confirmed class imbalance, we then split our dataset for training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns='flag_for_review')\n",
    "y = df['flag_for_review']\n",
    "\n",
    "# ===============================\n",
    "# Cross-Validation (Stability Check)\n",
    "# ===============================\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        max_iter=1000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "recall_scores = cross_val_score(\n",
    "    pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=cv,\n",
    "    scoring='recall'\n",
    ")\n",
    "\n",
    "print(\"Recall per fold:\", recall_scores)\n",
    "print(\"Mean recall:\", recall_scores.mean())\n",
    "print(\"Recall std:\", recall_scores.std())\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2afb89a9-c315-42e1-afd6-bed26760fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit scaler on training features only\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# We fit on training data\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb8cfc8-8e8c-4c95-97c1-b1d0dadbad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform test data using the scaler\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b717c-c239-48a3-acea-14cd5316982c",
   "metadata": {},
   "source": [
    "## Modeling Approach\n",
    "\n",
    "This problem is framed as a binary classification task.\n",
    "\n",
    "Logistic Regression is used as a baseline model due to its interpretability and suitability for clinical decision support.\n",
    "\n",
    "Because features operate on different numeric scales, feature scaling is applied.\n",
    "Class imbalance is addressed using class_weight='balanced'.\n",
    "\n",
    "Model performance is evaluated primarily using recall on the positive class,\n",
    "since missing a high-risk case is more dangerous than flagging a safe one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e3da9fc-c9b4-4828-8d14-cb73396ba3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We train the model on scaled data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686663bc-3c95-4eef-b9e0-10ec08bfccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  1]\n",
      " [ 4 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        42\n",
      "           1       0.99      0.94      0.96        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We evaluate properly\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94185bb-e981-40c7-aed7-2193d6096725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model already outputs probabilities, we were just throwing it away. Now we get probabilities instead of hard labels\n",
    "\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca19b11-bcd5-4277-84c7-2aaa5b1ba574",
   "metadata": {},
   "source": [
    "## Threshold Tuning\n",
    "\n",
    "By default, Logistic Regression uses a probability threshold of 0.5 to assign class labels.\n",
    "\n",
    "In this context, a 0.5 threshold may miss high-risk cases with moderately high predicted probabilities.\n",
    "To reduce false negatives, the decision threshold is lowered to 0.3.\n",
    "\n",
    "This adjustment intentionally increases sensitivity to high-risk cases\n",
    "while accepting an increase in manual review workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e30d0721-d9b7-45aa-9698-f8f9d1a4c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We try a lower threshold\n",
    "import numpy as np\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred_03 = (y_proba >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe3a64dc-c6e5-4a90-9c19-39403782214f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41  1]\n",
      " [ 0 72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        42\n",
      "           1       0.99      1.00      0.99        72\n",
      "\n",
      "    accuracy                           0.99       114\n",
      "   macro avg       0.99      0.99      0.99       114\n",
      "weighted avg       0.99      0.99      0.99       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We evaluate again\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_03))\n",
    "print(classification_report(y_test, y_pred_03))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76a822-13af-46f9-b761-07dbb97ecb71",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "Lowering the decision threshold reduces false negatives to zero in the test set.\n",
    "\n",
    "This demonstrates a clear trade-off:\n",
    "- Recall increases for high-risk cases\n",
    "- Precision decreases slightly due to more cases being flagged\n",
    "\n",
    "In a clinical context, this trade-off is acceptable,\n",
    "as patient safety is prioritized over operational convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05d93f0-4aec-49b5-8048-fefb75ebeeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision Recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Trade-off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb538f-72c7-4182-8ba0-c04c8ce02693",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The final model prioritizes recall to minimize false negatives in clinical risk flagging.\n",
    "\n",
    "Rather than automating decisions, the model supports clinicians\n",
    "by ensuring high-risk cases are consistently flagged for review.\n",
    "\n",
    "This approach aligns with real-world clinical safety and operational constraints."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
